from utils import get_vid

def prepare_ocr_visualization(mmif, view):
    """ Visualize OCR by extracting image frames with BoundingBoxes from video"""
    frames, text_docs, alignments = {}, {}, {}

    for anno in view.annotations:
        try:
            # Save frames w/ BoundingBoxes to "frames" dict
            if str(anno.at_type).endswith('BoundingBox'):
                frame_num = anno.properties["frame"]
                box_id = anno.properties["id"]
                boxType = anno.properties["boxType"]
                coordinates = anno.properties["coordinates"]
                x = coordinates[0][0]
                y = coordinates[0][1]
                w = coordinates[3][0] - x
                h = coordinates[3][1] - y
                box = [box_id, boxType, [x, y, w, h]]

                if frame_num in frames.keys():
                    frames[frame_num]["boxes"].append(box)
                    frames[frame_num]["bb_ids"].append(box_id)
                else:
                    frames[frame_num] = {"boxes": [box], "text": [], "bb_ids": [box_id], "timestamp": None, "secs": None, "repeat": False}

            elif str(anno.at_type).endswith('TextDocument'):
                t = anno.properties["text_value"]
                if t:
                    text_id = anno.properties["id"]
                    # Format string so it is JSON-readable
                    text_docs[text_id] = re.sub(r'[^\w]', '', t)

            elif str(anno.at_type).endswith('Alignment'):
                source = anno.properties["source"]
                target = anno.properties["target"]
                alignments[source] = target

        except Exception as e:
            print(f"Unexpected error of type {type(e)}: {e}")
            pass

    vid_path = get_video_path(mmif)
    frames_list = [(k, v) for k, v in frames.items()]
    return render_ocr(vid_path, frames_list, alignments, text_docs, 0, 1)


def render_ocr(vid_path, frames, alignments, text_docs, lower_n, upper_n):
    """Iterate through frames and display the contents/alignments."""
    # Read video as CV2 VideoCapture to extract screenshots + BoundingBoxes
    cv2_vid = cv2.VideoCapture(vid_path)
    fps = cv2_vid.get(cv2.CAP_PROP_FPS)
    # Path for storing temporary images generated by cv2
    tmp_path = '/app/static/tmp'
    if not os.path.exists(tmp_path):
        os.makedirs(tmp_path)

    prev_frame = {}
    i, upper_i = 0, upper_n
    while i <= upper_i:
        if i >= len(frames) or i < 0:
            break
        frame_num, frame = frames[i]
        # If frame has timestamp, it has already been processed
        # if frame["timestamp"]:
        #     break
        cv2_vid.set(1, frame_num)
        _, frame_cap = cv2_vid.read()
        with tempfile.NamedTemporaryFile(
            prefix="/app/static/tmp/", suffix=".jpg", delete=False) as tf:
            print(tf.name)
            cv2.imwrite(tf.name, frame_cap)
            # "id" is just the name of the temp image file
            frame["id"] = tf.name[12:]
            if fps:
                secs = int(frame_num/fps)
                frame["timestamp"] = datetime.timedelta(seconds=secs)
                frame["secs"] = secs
            for box_id in frame["bb_ids"]:
                text_id = alignments[box_id]
                frame["text"].append(text_docs[text_id])
            
            # Check for duplicates
            if is_duplicate_ocr_frame(frame, prev_frame):
                frame["repeat"] = True
                upper_i += 1

            prev_frame = frame
            i += 1

    return render_template('ocr.html', 
                           vid_path=vid_path, 
                           frames=frames, 
                           alignments=alignments, 
                           text_docs=text_docs, 
                           lower_n=lower_n, upper_n=upper_n)

def is_duplicate_ocr_frame(frame, prev_frame):
    if prev_frame:
        # Check Boundingbox distances
        rounded_prev = round_boxes(prev_frame["boxes"])
        for box in round_boxes(frame["boxes"]):
            if box in rounded_prev and frame["secs"]-prev_frame["secs"] < 5:
                return True
    return False

def round_boxes(boxes):
    # To account for jittery bounding boxes in OCR annotations
    rounded_boxes = []
    for box in boxes:
        rounded_box = []
        for coord in box[2]:
            rounded_box.append(round(coord/10)*10)
        rounded_boxes.append(rounded_box)
    return rounded_boxes

def get_ocr_views(mmif):
    """Return OCR views, which have TextDocument and Alignment annotations, but no
    other annotations."""
    views = []
    # TODO: not sure why we use the full URL
    needed_types = set([
        "http://mmif.clams.ai/0.4.0/vocabulary/TextDocument",
        "http://mmif.clams.ai/0.4.0/vocabulary/BoundingBox",
        "http://mmif.clams.ai/0.4.0/vocabulary/Alignment" ])
    for view in mmif.views:
        annotation_types = view.metadata.contains.keys()
        if needed_types.issubset(annotation_types) and len(annotation_types) == 3:
            views.append(view)
    return views